# M√î H√åNH DECISION TREE - PH√ÇN LO·∫†I CH·∫§T L∆Ø·ª¢NG KH√îNG KH√ç

## 1. T·ªîNG QUAN

**Thu·∫≠t to√°n**: Decision Tree Classifier (scikit-learn)  
**D·ªØ li·ªáu**: 1,804 m·∫´u t·ª´ `data_onkk (2).csv`

- Train: 1,443 m·∫´u (80%)
- Test: 361 m·∫´u (20%) - **ƒê√°nh gi√° ƒë·ªôc l·∫≠p**

**Features** (6 bi·∫øn kh√≠ t∆∞·ª£ng):

- PRES2M: √Åp su·∫•t kh√≠ quy·ªÉn (Pa)
- RH: ƒê·ªô ·∫©m t∆∞∆°ng ƒë·ªëi (%)
- WSPD: T·ªëc ƒë·ªô gi√≥ (m/s)
- TMP: Nhi·ªát ƒë·ªô (¬∞C)
- TP: L∆∞·ª£ng m∆∞a (mm)
- SQRT_SEA_DEM_LAT: Bi·∫øn ƒë·ªãa l√Ω t·ªïng h·ª£p

**Target**: 5 c·∫•p ƒë·ªô AQI d·ª±a tr√™n PM2.5

- T·ªët: ‚â§15.4 | Trung b√¨nh: 15.4-40.4 | K√©m: 40.4-65.4 | X·∫•u: 65.4-150.4 | R·∫•t x·∫•u: >150.4 Œºg/m¬≥

---

## 2. C√ÅCH X√ÇY D·ª∞NG M√î H√åNH

### 2.1 Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu

**Chu·∫©n h√≥a features** (StandardScaler):

```python
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

- C√¥ng th·ª©c: z = (x - Œº) / œÉ
- M·ª•c ƒë√≠ch: ƒê∆∞a c√°c features v·ªÅ c√πng t·ª∑ l·ªá

**M√£ h√≥a nh√£n** (LabelEncoder):

- Chuy·ªÉn text labels ‚Üí s·ªë (0-4)
- S·∫Øp x·∫øp alphabet: K√©m(0), R·∫•t x·∫•u(1), Trung b√¨nh(2), T·ªët(3), X·∫•u(4)

### 2.2 Hu·∫•n luy·ªán m√¥ h√¨nh

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split

# Chia d·ªØ li·ªáu (stratify ƒë·∫£m b·∫£o t·ª∑ l·ªá c√°c l·ªõp)
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
)

# Kh·ªüi t·∫°o v√† hu·∫•n luy·ªán
model = DecisionTreeClassifier(
    max_depth=10,
    min_samples_split=20,
    min_samples_leaf=10,
    random_state=42,
    class_weight='balanced'
)

model.fit(X_train_scaled, y_train)
```

---

## 3. T·ªêI ∆ØU THAM S·ªê

### 3.1 C√°c tham s·ªë ch√≠nh

| Tham s·ªë               | Gi√° tr·ªã    | L√Ω do ch·ªçn                                                                                    |
| --------------------- | ---------- | --------------------------------------------------------------------------------------------- |
| **max_depth**         | 10         | Gi·ªõi h·∫°n ƒë·ªô s√¢u c√¢y ‚Üí Tr√°nh overfitting, c√¢n b·∫±ng gi·ªØa ƒë·ªô ph·ª©c t·∫°p v√† kh·∫£ nƒÉng t·ªïng qu√°t      |
| **min_samples_split** | 20         | C·∫ßn ‚â•20 m·∫´u m·ªõi chia n√∫t ‚Üí Tr√°nh t·∫°o nh√°nh qu√° chi ti·∫øt v·ªõi √≠t d·ªØ li·ªáu                        |
| **min_samples_leaf**  | 10         | M·ªói n√∫t l√° ‚â•10 m·∫´u ‚Üí ƒê·∫£m b·∫£o quy·∫øt ƒë·ªãnh d·ª±a tr√™n ƒë·ªß b·∫±ng ch·ª©ng th·ªëng k√™                       |
| **class_weight**      | 'balanced' | T·ª± ƒë·ªông tƒÉng tr·ªçng s·ªë l·ªõp thi·ªÉu s·ªë ‚Üí X·ª≠ l√Ω m·∫•t c√¢n b·∫±ng d·ªØ li·ªáu (l·ªõp "X·∫•u", "R·∫•t x·∫•u" r·∫•t √≠t) |
| **random_state**      | 42         | Seed c·ªë ƒë·ªãnh ‚Üí ƒê·∫£m b·∫£o k·∫øt qu·∫£ t√°i t·∫°o ƒë∆∞·ª£c                                                   |

### 3.2 C√¥ng th·ª©c class_weight='balanced'

```
weight_class_i = n_samples / (n_classes √ó n_samples_class_i)
```

V√≠ d·ª• v·ªõi l·ªõp "R·∫•t x·∫•u" (ch·ªâ c√≥ 2 m·∫´u test):

- Tr·ªçng s·ªë cao h∆°n ‚Üí M√¥ h√¨nh ch√∫ √Ω nhi·ªÅu h∆°n
- K·∫øt qu·∫£: Recall = 100% (ph√°t hi·ªán c·∫£ 2 m·∫´u)

### 3.3 K·∫øt qu·∫£ sau hu·∫•n luy·ªán

- **ƒê·ªô s√¢u c√¢y th·ª±c t·∫ø**: 10 t·∫ßng
- **S·ªë n√∫t l√°**: 99 n√∫t
- **√ù nghƒ©a**: M√¥ h√¨nh t·∫°o ra 99 quy t·∫Øc ph√¢n lo·∫°i kh√°c nhau

---

## 4. K·∫æT QU·∫¢ TR√äN T·∫¨P TEST

### 4.1 Th√¥ng tin t·∫≠p Test

- **S·ªë m·∫´u**: 361 m·∫´u (20% t·ªïng d·ªØ li·ªáu)
- **ƒê·∫∑c ƒëi·ªÉm**: T·∫≠p ƒë·ªôc l·∫≠p, kh√¥ng tham gia hu·∫•n luy·ªán
- **Ph√¢n b·ªë c√°c l·ªõp**:
  - Trung b√¨nh: 190 m·∫´u (52.6%)
  - K√©m: 85 m·∫´u (23.5%)
  - T·ªët: 50 m·∫´u (13.9%)
  - X·∫•u: 34 m·∫´u (9.4%)
  - R·∫•t x·∫•u: 2 m·∫´u (0.6%)

### 4.2 Hi·ªáu su·∫•t t·ªïng th·ªÉ

```python
# D·ª± ƒëo√°n v√† ƒë√°nh gi√°
y_pred = model.predict(X_test_scaled)
accuracy = accuracy_score(y_test, y_pred)
```

| Metric                 | Gi√° tr·ªã    | √ù nghƒ©a                                    | So v·ªõi Neural Network |
| ---------------------- | ---------- | ------------------------------------------ | --------------------- |
| **Accuracy**           | **60.11%** | T·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng t·ªïng th·ªÉ                | +4.95% (55.16%)       |
| **Weighted Precision** | 0.6449     | ƒê·ªô ch√≠nh x√°c c√≥ tr·ªçng s·ªë theo s·ªë l∆∞·ª£ng m·∫´u | +0.0050 (0.6399)      |
| **Weighted Recall**    | 0.6011     | ƒê·ªô ph·ªß c√≥ tr·ªçng s·ªë                         | +0.0495 (0.5516)      |
| **Weighted F1**        | 0.6098     | Trung b√¨nh ƒëi·ªÅu h√≤a P-R c√≥ tr·ªçng s·ªë        | +0.0560 (0.5538)      |
| **Macro F1**           | 0.5388     | Trung b√¨nh F1 c√°c l·ªõp (kh√¥ng tr·ªçng s·ªë)     | +0.1436 (0.3952)      |

**ƒê√°nh gi√°**: Decision Tree v∆∞·ª£t tr·ªôi h∆°n Neural Network ·ªü t·∫•t c·∫£ c√°c ch·ªâ s·ªë, ƒë·∫∑c bi·ªát Macro F1 (+14.36%)

#### 4.3 Classification Report

![Classification Report](decision_tree_classification_report.png)

**Hi·ªáu su·∫•t t·ª´ng l·ªõp (Class-wise Performance)**:

| L·ªõp            | Precision | Recall   | F1-Score | Support | Ph√¢n t√≠ch                                                      |
| -------------- | --------- | -------- | -------- | ------- | -------------------------------------------------------------- |
| **T·ªët**        | 0.59      | **0.78** | 0.67     | 50      | ‚úÖ Recall cao (39/50) - Ph√°t hi·ªán t·ªët c√°c ng√†y ch·∫•t l∆∞·ª£ng t·ªët  |
| **Trung b√¨nh** | **0.79**  | 0.59     | 0.68     | 190     | ‚úÖ Precision cao nh·∫•t - D·ª± ƒëo√°n ch√≠nh x√°c nh·∫•t (113/190 ƒë√∫ng)  |
| **K√©m**        | 0.45      | 0.47     | 0.46     | 85      | ‚ö†Ô∏è Trung b√¨nh - Hay nh·∫ßm v·ªõi "Trung b√¨nh" (18) v√† "X·∫•u" (24)   |
| **X·∫•u**        | 0.43      | **0.68** | 0.52     | 34      | ‚úÖ Recall cao (23/34) - Quan tr·ªçng cho c·∫£nh b√°o!               |
| **R·∫•t x·∫•u**    | 0.22      | **1.00** | 0.36     | 2       | ‚úÖ Ph√°t hi·ªán 100% (2/2) - Nh∆∞ng nhi·ªÅu false positive do √≠t m·∫´u |

### 4.4 Ph√¢n t√≠ch chi ti·∫øt

**üéØ ƒêi·ªÉm m·∫°nh (Strengths)**:

1. **C·∫£nh b√°o s·ªõm hi·ªáu qu·∫£**:

   - L·ªõp "X·∫•u": Recall = 0.68 ‚Üí Ph√°t hi·ªán 23/34 tr∆∞·ªùng h·ª£p nguy hi·ªÉm
   - L·ªõp "R·∫•t x·∫•u": Recall = 1.00 ‚Üí Kh√¥ng b·ªè s√≥t (2/2)
   - Quan tr·ªçng trong gi√°m s√°t m√¥i tr∆∞·ªùng: ∆Øu ti√™n ph√°t hi·ªán nguy c∆° h∆°n l√† gi·∫£m b√°o ƒë·ªông gi·∫£

2. **ƒê·ªô ch√≠nh x√°c cao cho l·ªõp ph·ªï bi·∫øn**:

   - "Trung b√¨nh": Precision = 0.79 ‚Üí Khi d·ª± ƒëo√°n "Trung b√¨nh", c√≥ 79% ƒë√∫ng
   - ƒê√≥ng g√≥p ch√≠nh v√†o accuracy t·ªïng th·ªÉ

3. **X·ª≠ l√Ω t·ªët d·ªØ li·ªáu m·∫•t c√¢n b·∫±ng**:
   - Nh·ªù `class_weight='balanced'`, c√°c l·ªõp thi·ªÉu s·ªë v·∫´n ƒë·∫°t Recall cao

**‚ö†Ô∏è H·∫°n ch·∫ø (Limitations)**:

1. **Accuracy ch∆∞a cao** (60.11%):

   - V·∫´n c√≤n 144/361 d·ª± ƒëo√°n sai (39.89%)
   - C·∫ßn c·∫£i thi·ªán th√™m

2. **L·ªõp "K√©m" v√† "X·∫•u" k√©m ·ªïn ƒë·ªãnh**:

   - F1-Score ch·ªâ ƒë·∫°t 0.46 v√† 0.52
   - Precision th·∫•p ‚Üí Nhi·ªÅu false positives

3. **Xu h∆∞·ªõng nh·∫ßm l·∫´n gi·ªØa c√°c l·ªõp l√¢n c·∫≠n**:
   - "K√©m" ‚Üî "Trung b√¨nh": 61 tr∆∞·ªùng h·ª£p
   - "K√©m" ‚Üî "X·∫•u": 30 tr∆∞·ªùng h·ª£p
   - Do t√≠nh li√™n t·ª•c c·ªßa n·ªìng ƒë·ªô PM2.5

### 4.5 So s√°nh v·ªõi Neural Network

| Model              | Accuracy   | Weighted F1 | Macro F1    | ƒêi·ªÉm m·∫°nh                              |
| ------------------ | ---------- | ----------- | ----------- | -------------------------------------- |
| **Neural Network** | 55.16%     | 0.5538      | 0.3952      | H·ªçc ƒë∆∞·ª£c pattern ph·ª©c t·∫°p              |
| **Decision Tree**  | **60.11%** | **0.6098**  | **0.5388**  | D·ªÖ di·ªÖn gi·∫£i, Recall cao l·ªõp nguy hi·ªÉm |
| **C·∫£i thi·ªán**      | **+4.95%** | **+5.6%**   | **+14.36%** | -                                      |

**K·∫øt lu·∫≠n**: Decision Tree v∆∞·ª£t tr·ªôi v·ªÅ kh·∫£ nƒÉng c·∫£nh b√°o s·ªõm v√† d·ªÖ di·ªÖn gi·∫£i

---

## 11. Evaluation details (full)

### Classification report (scikit-learn)

```
              precision    recall  f1-score   support

         K√©m       0.45      0.47      0.46        85
     R·∫•t x·∫•u       0.22      1.00      0.36         2
  Trung b√¨nh       0.79      0.59      0.68       190
         T·ªët       0.59      0.78      0.67        50
         X·∫•u       0.43      0.68      0.52        34

    accuracy                           0.60       361
   macro avg       0.50      0.70      0.54       361
weighted avg       0.64      0.60      0.61       361
```

### Confusion matrix

The confusion matrix (rows = actual, columns = predicted):

```
[[39, 10, 0, 0, 1],
 [26, 113, 43, 2, 6],
 [0, 18, 40, 3, 24],
 [0, 2, 6, 2, 24],
 [1, 1, 0, 0, 0]]
```

Interpretation: each row corresponds to the true class in logical order [T·ªët, Trung b√¨nh, K√©m, X·∫•u, R·∫•t x·∫•u].

### Training history / summary

- Training accuracy (on train set): 0.6784
- Test accuracy: 0.6011
- Weighted F1 (test): 0.6098
- Decision tree depth: 10
- Number of leaves: 99
- Training & prediction time (measured): 0.0009 s (prediction on test set)
- 5-fold cross-validation accuracy mean/std: 0.3680 ¬± 0.0886

Note: Decision Trees do not produce epoch-by-epoch training history like neural networks. For model stability we report 5-fold CV scores above; consider using ensemble methods (Random Forest) for more stable CV performance.

---

## 5. PH√ÇN PH·ªêI D·ªÆ LI·ªÜU (Class Distribution)

![Class Distribution Train vs Test](decision_tree_class_distribution.png)

**Nh·∫≠n x√©t**: 
- L·ªõp "Trung b√¨nh" chi·∫øm ƒëa s·ªë (~52% train, ~53% test)
- L·ªõp "R·∫•t x·∫•u" r·∫•t hi·∫øm (1.4% train, 0.6% test)
- Ph√¢n chia train/test gi·ªØ t·ª∑ l·ªá ƒë·ªìng ƒë·ªÅu nh·ªù `stratify=y_encoded`

---

## 6. FEATURE IMPORTANCE

![Feature Importance Chart](decision_tree_feature_importance.png)

**B·∫£ng x·∫øp h·∫°ng**:

| Th·ª© h·∫°ng | Feature              | Importance | Gi·∫£i th√≠ch                 |
| -------- | -------------------- | ---------- | -------------------------- |
| 1        | **PRES2M**           | 29.30%     | √Åp su·∫•t th·∫•p ‚Üí B·ª•i ·ª© ƒë·ªçng  |
| 2        | **SQRT_SEA_DEM_LAT** | 21.97%     | Y·∫øu t·ªë ƒë·ªãa l√Ω t·ªïng h·ª£p     |
| 3        | **TP**               | 20.82%     | M∆∞a l·ªõn ‚Üí R·ª≠a tr√¥i b·ª•i     |
| 4        | TMP                  | 11.59%     | Nhi·ªát ƒë·ªô ·∫£nh h∆∞·ªüng h√≥a h·ªçc |
| 5        | RH                   | 8.43%      | ƒê·ªô ·∫©m - k·∫øt t·ª• b·ª•i         |
| 6        | WSPD                 | 7.88%      | Gi√≥ - ph√¢n t√°n b·ª•i         |

---

## 7. MA TR·∫¨N NH·∫¶M L·∫™N

![Confusion Matrix Heatmap](decision_tree_confusion_matrix.png)

**B·∫£ng s·ªë li·ªáu** (h√†ng = th·ª±c t·∫ø, c·ªôt = d·ª± ƒëo√°n):

|                | T·ªët    | Trung b√¨nh | K√©m  | X·∫•u  | R·∫•t x·∫•u |
| -------------- | ------ | ---------- | ---- | ---- | ------- |
| **T·ªët**        | **39** | 10         | 0    | 0    | 1       |
| **Trung b√¨nh** | 26     | **113**    | 43   | 2    | 6       |
| **K√©m**        | 0      | 18         | **40** | 3    | 24      |
| **X·∫•u**        | 0      | 2          | 6    | 2    | **24**  |
| **R·∫•t x·∫•u**    | 1      | 1          | 0    | 0    | **0**   |

**Nh·∫≠n x√©t**: Sai s·ªë t·∫≠p trung ·ªü c√°c l·ªõp l√¢n c·∫≠n (Trung b√¨nh ‚Üî K√©m, K√©m ‚Üî X·∫•u). Heatmap cho th·∫•y ƒë∆∞·ªùng ch√©o ch√≠nh (d·ª± ƒëo√°n ƒë√∫ng) c√≥ m√†u ƒë·∫≠m h∆°n.

---

## 8. ∆ØU ƒêI·ªÇM & H·∫†N CH·∫æ (T·ªïng h·ª£p)

### ‚úÖ ∆Øu ƒëi·ªÉm

- Hi·ªáu su·∫•t v∆∞·ª£t Neural Network (+4.95%)
- Recall cao cho l·ªõp nguy hi·ªÉm (c·∫£nh b√°o s·ªõm t·ªët)
- D·ªÖ di·ªÖn gi·∫£i, c√≥ th·ªÉ tr√≠ch xu·∫•t quy t·∫Øc
- X·ª≠ l√Ω t·ªët d·ªØ li·ªáu m·∫•t c√¢n b·∫±ng

### ‚ö†Ô∏è H·∫°n ch·∫ø

- Accuracy 60% ch∆∞a cao
- L·ªõp "K√©m" v√† "X·∫•u" c√≤n nhi·ªÅu nh·∫ßm l·∫´n
- D·ªØ li·ªáu "R·∫•t x·∫•u" qu√° √≠t (ch·ªâ 2 m·∫´u test)

---

## 9. ·ª®NG D·ª§NG

**T·∫°o b·∫£n ƒë·ªì AQI t·ª´ d·ªØ li·ªáu v·ªá tinh**:

- Input: TIF files (PRES2M, RH, WSPD, TMP, TP)
- Output: B·∫£n ƒë·ªì m√†u + CSV predictions
- ƒê√£ x·ª≠ l√Ω: 6 ng√†y (20200101, 20200529, 20200721, 20200810, 20201015, 20201215)

**Color mapping** (theo th·ª© t·ª± logic):

- Xanh l√° (#00E400): T·ªët
- V√†ng (#FFFF00): Trung b√¨nh
- Cam (#FF7E00): K√©m
- ƒê·ªè (#FF0000): X·∫•u
- T√≠m (#8F3F97): R·∫•t x·∫•u

### 9.1 K·∫øt qu·∫£ b·∫£n ƒë·ªì AQI

**Ng√†y 01/01/2020** (M√πa ƒë√¥ng):
![AQI Map 20200101](../output_images_dt/AQI_Map_DT_20200101.png)

**Ng√†y 29/05/2020** (Cu·ªëi xu√¢n):
![AQI Map 20200529](../output_images_dt/AQI_Map_DT_20200529.png)

**Ng√†y 21/07/2020** (M√πa h√®):
![AQI Map 20200721](../output_images_dt/AQI_Map_DT_20200721.png)

**Ng√†y 10/08/2020** (M√πa h√®):
![AQI Map 20200810](../output_images_dt/AQI_Map_DT_20200810.png)

**Ng√†y 15/10/2020** (M√πa thu):
![AQI Map 20201015](../output_images_dt/AQI_Map_DT_20201015.png)

**Ng√†y 15/12/2020** (M√πa ƒë√¥ng):
![AQI Map 20201215](../output_images_dt/AQI_Map_DT_20201215.png)

**Nh·∫≠n x√©t**:
- Ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ thay ƒë·ªïi theo m√πa
- M√πa h√® (th√°ng 7-8): Nhi·ªÅu v√πng "T·ªët" (xanh l√°) do m∆∞a nhi·ªÅu
- M√πa ƒë√¥ng (th√°ng 12-1): Xu·∫•t hi·ªán nhi·ªÅu v√πng "K√©m" v√† "X·∫•u" (cam, ƒë·ªè) h∆°n

---

## 10. KHUY·∫æN NGH·ªä C·∫¢I THI·ªÜN

1. **Thu th·∫≠p th√™m d·ªØ li·ªáu** l·ªõp "X·∫•u" v√† "R·∫•t x·∫•u"
2. **√Åp d·ª•ng SMOTE** ƒë·ªÉ t·∫°o m·∫´u t·ªïng h·ª£p cho l·ªõp thi·ªÉu s·ªë
3. **Ensemble methods**: Random Forest, XGBoost ‚Üí TƒÉng accuracy l√™n 65-70%
4. **Feature engineering**: Th√™m bi·∫øn t∆∞∆°ng t√°c, d·ªØ li·ªáu temporal

---

**K·∫øt lu·∫≠n**: Decision Tree ƒë·∫°t 60.11% accuracy, v∆∞·ª£t tr·ªôi Neural Network 4.95%. M√¥ h√¨nh ph√π h·ª£p cho h·ªá th·ªëng c·∫£nh b√°o s·ªõm v·ªõi Recall cao tr√™n l·ªõp nguy hi·ªÉm, d·ªÖ di·ªÖn gi·∫£i v√† tri·ªÉn khai th·ª±c t·∫ø.
